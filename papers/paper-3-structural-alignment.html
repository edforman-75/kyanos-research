<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Paper III: Evidence Asymmetry and Structural Alignment | KyanosTech Research</title>
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>
    <header class="site-header">
        <div class="site-header-inner">
            <a href="../index.html" class="site-logo">KyanosTech Research</a>
                        <nav class="site-nav">
                <a href="../index.html">Research</a>
                <div class="nav-dropdown">
                    <span class="nav-dropdown-trigger">Papers ▾</span>
                    <div class="nav-dropdown-content">
                        <a href="paper-1-synthesis.html">I. The Case for Progressive AI Infrastructure</a>
                        <a href="paper-2-gatekeeper.html">II. AI as the New Information Gatekeeper</a>
                        <a href="paper-3-structural-alignment.html">III. Evidence Asymmetry and Structural Alignment</a>
                        <a href="paper-4-neutrality.html">IV. The Impossibility of Political Neutrality</a>
                        <a href="paper-5-structured-data.html">V. Structured Data as Independent Value</a>
                        <a href="paper-6-technical-pathways.html">VI. Technical Pathways to AI Visibility</a>
                    </div>
                </div>
                <div class="nav-dropdown">
                    <span class="nav-dropdown-trigger">Appendices ▾</span>
                    <div class="nav-dropdown-content">
                        <a href="../appendices/appendix-a-market-dynamics.html">A. Market Dynamics</a>
                        <a href="../appendices/appendix-b-voter-ai-usage.html">B. Voter AI Usage Projections</a>
                        <a href="../appendices/appendix-c-cost-per-vote-roi.html">C. Cost-Per-Vote ROI Analysis</a>
                        <a href="../appendices/appendix-d-monte-carlo.html">D. Monte Carlo Simulation</a>
                        <a href="../appendices/appendix-e-workflow-demo.html">E. Campaign Workflow Demo</a>
                        <a href="../appendices/appendix-f-demographic-convergence.html">F. Demographic Convergence</a>
                    </div>
                </div>
                <a href="../about.html">About</a>
            </nav>
        </div>
    </header>

    <div class="paper-header">
        <div class="paper-header-inner">
            <div class="paper-series">Paper III</div>
            <h1 class="paper-title">Evidence Asymmetry and Structural Alignment</h1>
            <p class="paper-subtitle">How Progressive Communication Patterns Align with AI Training Objectives</p>
            <div class="paper-meta">
                <span class="author">Ed Forman</span> with Claude (Anthropic)  -  December 2025
            </div>
        </div>
    </div>

    <div class="container">
        <div class="abstract">
            <div class="abstract-label">Abstract</div>
            <p>This paper examines documented asymmetries in how American political coalitions use evidence, citations, and empirical reasoning. Drawing on computational analysis of congressional speeches, congressional committee citation patterns, and fact-checking data, it demonstrates that Democratic communication consistently exhibits higher rates of scholarly citation, evidence-based rhetoric, and factual accuracy. Because AI systems are trained to prioritize well-sourced, evidence-based content, these asymmetries suggest a potential structural alignment between progressive communication patterns and AI credibility signals-an alignment that exists independent of any intentional bias in AI systems.</p>
        </div>

        <h2><span class="section-number">I.</span> The Evidence Question</h2>

        <p>A persistent finding across multiple research methodologies is that American political coalitions differ systematically in how they use evidence, cite sources, and employ empirical reasoning. This paper synthesizes research from computational linguistics, political science, and media studies to document these asymmetries and explore their implications for AI-mediated political communication.</p>

        <p>The central argument is structural rather than evaluative. We do not argue that one coalition is "better" than another, or that evidence-based communication is inherently superior to values-based appeals. Instead, we document an empirical pattern and explore its implications: <span class="highlight">if AI systems are trained to prioritize evidence-based, well-sourced content, and if one political coalition systematically produces more of such content, then AI outputs will reflect this asymmetry regardless of any intentional bias</span>.</p>

        <p>This analysis has practical implications for political organizations. If the alignment between progressive communication and AI training objectives is real, it represents a structural advantage that organizations can either leverage or squander. Understanding the mechanism is the first step.</p>

        <h2><span class="section-number">II.</span> Congressional Citation Patterns</h2>

        <h3>A. Partisan Differences in Scientific Citation</h3>

        <p>A 2025 study examining more than 49,000 congressional committee reports and hearing documents from 1995 to 2021 found systematic differences in how Democratic and Republican-led committees cite scientific research.<sup class="fn-ref"><a href="#fn1" id="fn1-ref">1</a></sup></p>

        <p>The research, posted on the SocArXiv preprint database and reported in <em>Science</em>, revealed several key findings:</p>

        <div class="callout callout-evidence">
            <div class="callout-label">Research Finding</div>
            <p><strong>Citation Rate:</strong> Committees under Democratic control were almost twice as likely to cite technical papers as panels led by Republicans.</p>
            <p><strong>Citation Quality:</strong> Democrat-led committees were more likely to cite papers that were recent, had undergone peer review, and were widely cited among scientists.</p>
            <p><strong>Citation Overlap:</strong> Only about 5% of cited papers drew a reference from both sides at least once during the study period.<sup class="fn-ref"><a href="#fn2" id="fn2-ref">2</a></sup></p>
        </div>

        <p>The researchers found similar ideological discrepancies when they examined more than 191,000 reports published by 121 U.S. think tanks that clearly lean to the left or right on the political spectrum. Left-leaning think tanks cited research papers more frequently and cited higher-quality sources than right-leaning counterparts.</p>

        <p>As sociologist Thomas Dietz of Michigan State University noted, "This is the first [study] I've seen that documents in detail how [political polarization] plays out in policy documents themselves."<sup class="fn-ref"><a href="#fn3" id="fn3-ref">3</a></sup></p>

        <h3>B. The Evidence-Intuition Spectrum</h3>

        <p>A comprehensive 2025 study published in <em>Nature Human Behaviour</em> analyzed 8 million congressional speeches from 1879 to 2022, measuring the balance between evidence-based and intuition-based rhetoric.<sup class="fn-ref"><a href="#fn4" id="fn4-ref">4</a></sup></p>

        <p>The researchers developed an "Evidence-Minus-Intuition" (EMI) score using validated dictionaries of keywords. Evidence-based language included terms like "fact," "data," "evidence," "analyze," "research," and "findings." Intuition-based language included terms like "believe," "feel," "opinion," "common sense," "guess," and "point of view."</p>

        <p>The study's key findings:</p>

        <ul>
            <li><strong>Historical Decline:</strong> Evidence-based language in Congress has declined continuously since the mid-1970s, reaching a historic low in the 2021-2022 session.</li>
            <li><strong>Bipartisan Trend:</strong> Both parties show declining use of evidence-based rhetoric over time.</li>
            <li><strong>Recent Divergence:</strong> The steepest decline in evidence-based speech during the 2021-2022 session came from Republicans, creating a widening gap between the parties.<sup class="fn-ref"><a href="#fn5" id="fn5-ref">5</a></sup></li>
        </ul>

        <p>The researchers found that this linguistic shift correlates with decreased legislative productivity and increased political polarization. When Congress uses less evidence-based language, fewer significant laws get passed.</p>

        <div class="callout callout-key">
            <div class="callout-label">Key Finding</div>
            <p>"Exclusive reliance on intuition may prevent productive political debate because evidence and data can no longer adjudicate between competing political positions."<sup class="fn-ref"><a href="#fn6" id="fn6-ref">6</a></sup></p>
        </div>

        <h2><span class="section-number">III.</span> Fact-Checking Asymmetries</h2>

        <h3>A. Systematic Accuracy Differences</h3>

        <p>Multiple independent studies of fact-checking data have found consistent asymmetries in accuracy rates between political parties. While these findings are contested-with some arguing they reflect selection bias in what claims are checked-the pattern is remarkably consistent across time periods, fact-checking organizations, and methodologies.</p>

        <p>The Center for Media and Public Affairs at George Mason University conducted a series of studies examining PolitiFact ratings. A 2013 study found:</p>

        <ul>
            <li>Republican claims rated "false" or "pants on fire": 32%</li>
            <li>Democratic claims rated "false" or "pants on fire": 11%</li>
            <li>Republican claims rated "entirely true": 11%</li>
            <li>Democratic claims rated "entirely true": 22%<sup class="fn-ref"><a href="#fn7" id="fn7-ref">7</a></sup></li>
        </ul>

        <p>In October 2024, upon his retirement from PolitiFact, founder Bill Adair stated that based on the organization's accumulated data, Republicans made false claims more often than Democrats, by a margin of 55% to 31%.<sup class="fn-ref"><a href="#fn8" id="fn8-ref">8</a></sup></p>

        <h3>B. Interpreting the Asymmetry</h3>

        <p>These findings admit multiple interpretations:</p>

        <p><strong>Selection Bias Hypothesis:</strong> Fact-checkers may disproportionately select Republican claims for checking, particularly claims that appear false. University of Minnesota political scientist Eric Ostermeier raised this concern in a 2011 analysis, noting that PolitiFact was not transparent about how statements were selected for analysis.<sup class="fn-ref"><a href="#fn9" id="fn9-ref">9</a></sup></p>

        <p><strong>Differential Accuracy Hypothesis:</strong> One coalition may systematically make more accurate empirical claims than the other. This could reflect different relationships to expertise, institutions, or empirical reasoning.</p>

        <p><strong>Rhetorical Strategy Hypothesis:</strong> Different coalitions may emphasize different types of claims-one emphasizing empirically testable statements, the other emphasizing values and interpretations that cannot be fact-checked.</p>

        <div class="callout callout-limitation">
            <div class="callout-label">Limitations</div>
            <p>We cannot definitively adjudicate between these hypotheses. However, for the purposes of understanding AI system behavior, the relevant fact is that fact-checking content-which is indexed, crawled, and incorporated into AI training data-consistently shows higher false ratings for Republican claims. This content, regardless of its ultimate accuracy, influences how AI systems represent political figures and claims.</p>
        </div>

        <h2><span class="section-number">IV.</span> How AI Systems Use Evidence Signals</h2>

        <h3>A. Training Data and Quality Signals</h3>

        <p>Large language models learn from vast corpora of text, including academic papers, news articles, government documents, and web content. Through training, these models internalize patterns about what constitutes credible, well-supported information.</p>

        <p>Research on AI systems reveals that they exhibit "prestige-linked priors"-tendencies to weight information from high-prestige institutions more heavily.<sup class="fn-ref"><a href="#fn10" id="fn10-ref">10</a></sup> A 2025 audit study found that LLMs exhibit strong institutional-prestige bias, with papers attributed to high-prestige universities receiving more favorable evaluations than identical papers attributed to lower-prestige institutions.</p>

        <p>These biases are not intentionally programmed but emerge from training data that itself reflects prestige hierarchies. Similarly, AI systems trained on content that correlates citations, peer review, and empirical methodology with credibility will internalize these correlations.</p>

        <h3>B. Retrieval-Augmented Generation</h3>

        <p>Modern AI systems increasingly use Retrieval-Augmented Generation (RAG), searching external databases to supplement their training. When answering questions, these systems retrieve relevant documents and synthesize answers from retrieved content.<sup class="fn-ref"><a href="#fn11" id="fn11-ref">11</a></sup></p>

        <p>RAG systems prioritize sources based on quality signals including:</p>

        <ul>
            <li><strong>Domain authority:</strong> Content from recognized institutions and established publishers</li>
            <li><strong>Recency:</strong> More recent information for time-sensitive queries</li>
            <li><strong>Citation patterns:</strong> Content that cites sources and is itself cited</li>
            <li><strong>Structured data:</strong> Content with clear metadata and semantic markup</li>
            <li><strong>Verifiability:</strong> Claims that can be cross-referenced with other sources</li>
        </ul>

        <p>These quality signals are not politically neutral. If one coalition's communications more frequently include citations, reference peer-reviewed research, and employ structured data, those communications will be preferentially retrieved and synthesized by AI systems.</p>

        <h3>C. The E-E-A-T Framework</h3>

        <p>Google's E-E-A-T framework (Experience, Expertise, Authoritativeness, Trustworthiness) influences both traditional search rankings and AI-generated content. Industry research suggests that LLMs "rely heavily on Google's E-E-A-T principles to assess reliability."<sup class="fn-ref"><a href="#fn12" id="fn12-ref">12</a></sup></p>

        <p>Content that demonstrates expertise through citations, establishes authority through institutional affiliations, and builds trust through transparent sourcing will perform better in AI environments than content that relies on assertion, emotional appeal, or appeals to common sense.</p>

        <h2><span class="section-number">V.</span> The Structural Alignment Hypothesis</h2>

        <h3>A. Connecting the Evidence</h3>

        <p>The evidence presented above suggests a structural alignment between progressive communication patterns and AI training objectives:</p>

        <ol>
            <li><strong>Citation Asymmetry:</strong> <span class="highlight">Democratic communications cite scholarly sources at nearly twice the rate of Republican communications</span>.</li>
            <li><strong>Evidence-Based Rhetoric:</strong> While both parties have shifted toward intuition-based language, Democrats maintain higher levels of evidence-based rhetoric.</li>
            <li><strong>Fact-Check Performance:</strong> Democratic claims receive "true" ratings at higher rates, generating positive credibility signals in indexed content.</li>
            <li><strong>AI Quality Signals:</strong> AI systems are trained to prioritize well-sourced, evidence-based content with strong institutional affiliations.</li>
        </ol>

        <p>The logical conclusion: if AI systems prioritize evidence-based, well-cited content, and if Democratic communications more frequently exhibit these characteristics, then AI outputs will naturally favor Democratic perspectives-not because of intentional bias, but because of structural alignment between communication patterns and training objectives.</p>

        <div class="callout callout-key">
            <div class="callout-label">Central Thesis</div>
            <p><span class="highlight">The apparent "liberal bias" in AI systems may be largely explained by structural alignment between progressive communication patterns and the evidence-based quality signals that AI systems are trained to prioritize.</span> This alignment exists independent of any intentional bias on the part of AI developers.</p>
        </div>

        <h3>B. The Truth-Bias Connection</h3>

        <p>This structural alignment hypothesis connects to the "truth-bias paradox" documented in <a href="paper-4-neutrality.html">Paper IV</a>. The MIT research finding that optimizing for truthfulness produces left-leaning outputs may not reflect bias in the training process but rather a genuine correlation between truthfulness and left-leaning content in the training data.<sup class="fn-ref"><a href="#fn13" id="fn13-ref">13</a></sup></p>

        <p>If progressive communications more frequently cite accurate sources, employ evidence-based reasoning, and receive "true" ratings from fact-checkers, then a system optimized for truth will naturally produce outputs aligned with progressive positions-not because truth is inherently progressive, but because progressive communications more consistently exhibit the patterns that AI systems interpret as truth signals.</p>

        <h2><span class="section-number">VI.</span> Strategic Implications</h2>

        <h3>A. The Opportunity</h3>

        <p>If the structural alignment hypothesis is correct, progressive organizations have an opportunity that conservative organizations do not: their natural communication patterns align with AI training objectives. This alignment can be leveraged through:</p>

        <ul>
            <li><strong>Enhanced Citation Practices:</strong> Making explicit what progressive communications already do implicitly-citing sources, referencing research, and building arguments on empirical foundations.</li>
            <li><strong>Structured Data Investment:</strong> Encoding evidence-based claims in formats that AI systems can parse and verify (see <a href="paper-5-structured-data.html">Paper V</a>).</li>
            <li><strong>Institutional Partnerships:</strong> Leveraging relationships with universities, research organizations, and credentialed experts to strengthen authority signals.</li>
        </ul>

        <h3>B. The Risk of Squandering</h3>

        <p>Structural alignment is an advantage only if it is recognized and leveraged. Progressive organizations that:</p>

        <ul>
            <li>Fail to invest in structured data infrastructure</li>
            <li>Adopt the emotional and assertion-based rhetoric of their opponents</li>
            <li>Neglect to make their evidence-based arguments machine-readable</li>
        </ul>

        <p>...will squander a natural advantage and find themselves at a disadvantage as AI systems become primary information gatekeepers.</p>

        <h3>C. The Rhetorical Opportunity</h3>

        <p>Beyond infrastructure, there is a rhetorical opportunity. If AI systems favor evidence-based communication, progressive campaigns and causes can be coached to emphasize:</p>

        <ul>
            <li><strong>Specific citations</strong> rather than general appeals to authority</li>
            <li><strong>Empirical claims</strong> rather than values-based assertions</li>
            <li><strong>Data and statistics</strong> rather than anecdotes and emotional appeals</li>
            <li><strong>Expert consensus</strong> rather than individual opinions</li>
        </ul>

        <p>This is not a call to abandon values-based communication-moral framing remains essential for political mobilization. Rather, it suggests that progressive communicators should ensure their evidence-based advantages are not obscured by rhetorical choices that fail to signal them.</p>

        <h2><span class="section-number">VII.</span> Limitations and Counter-Arguments</h2>

        <h3>A. Correlation vs. Causation</h3>

        <p>We have documented correlations-between political orientation and citation patterns, between citation patterns and AI quality signals-but have not established causal mechanisms. It is possible that other factors explain both the citation asymmetries and AI output patterns.</p>

        <h3>B. Evolving Systems</h3>

        <p>AI systems are updated frequently, and the relationship between evidence signals and political orientation may change. Conservative organizations may invest in citation-heavy communications. AI companies may adjust their systems to reduce perceived political bias. The structural alignment documented here is a snapshot, not a permanent condition.</p>

        <h3>C. Quality of Evidence</h3>

        <p>The evidence presented here varies in strength. The congressional citation study and the EMI analysis are peer-reviewed research with large samples. The fact-checking data is more contested. Readers should weight findings accordingly.</p>

        <h3>D. Alternative Explanations</h3>

        <p>The structural alignment hypothesis is one explanation for observed AI political patterns. Alternative explanations include:</p>

        <ul>
            <li>Intentional bias by AI developers</li>
            <li>Geographic and demographic biases in training data sources</li>
            <li>Artifacts of specific training choices rather than structural features</li>
        </ul>

        <p>We do not claim that structural alignment is the sole explanation, only that it is a significant contributing factor that has been underexplored.</p>

        <h2><span class="section-number">VIII.</span> Conclusion</h2>

        <p>The evidence supports three conclusions:</p>

        <ol>
            <li><strong>Evidence asymmetries are documented and consistent.</strong> Multiple independent methodologies find that Democratic communications cite more sources, employ more evidence-based rhetoric, and receive higher accuracy ratings from fact-checkers.</li>
            <li><strong>AI systems are trained to prioritize evidence signals.</strong> Citation patterns, institutional authority, and verifiability are quality signals that influence how AI systems retrieve and synthesize information.</li>
            <li><strong>Structural alignment creates opportunity.</strong> Progressive organizations have natural communication patterns that align with AI training objectives-an advantage that can be leveraged or squandered.</li>
        </ol>

        <p>For campaigns and causes, the practical implication is clear: the shift toward AI-mediated information access creates an environment where evidence-based communication has structural advantages. Organizations that invest in making their evidence-based arguments visible to AI systems-through structured data, enhanced citation practices, and rhetorical strategies that emphasize empirical foundations-will be better positioned in the emerging information landscape.</p>

        <blockquote>
            <p>"The question is not whether AI systems will have political patterns-they necessarily will. The question is whether organizations understand those patterns and position themselves accordingly."</p>
        </blockquote>

        <p class="cross-ref"><em>For the evidence that AI systems are becoming primary information gatekeepers, see <a href="paper-2-gatekeeper.html">Paper II</a>. For the case that political neutrality is impossible, see <a href="paper-4-neutrality.html">Paper IV</a>. For the technical pathway forward, see <a href="paper-5-structured-data.html">Paper V</a>.</em></p>

        <div class="footnotes">
            <h2>Notes</h2>

            <p class="footnote-item" id="fn1"><strong>[1]</strong> The study examined congressional committee documents from 1995-2021. Reported in Jeffrey Mervis, "Congress is using more science, but the two parties rarely cite the same studies," <em>Science</em>, April 24, 2025. The study was posted on the SocArXiv preprint database. <a href="https://www.science.org/content/article/congress-using-more-science-two-parties-rarely-cite-same-studies" target="_blank">Science</a> <a href="#fn1-ref">↩</a></p>

            <p class="footnote-item" id="fn2"><strong>[2]</strong> Ibid. The 5% overlap figure is particularly striking-it suggests that Democratic and Republican committees are drawing on almost entirely separate bodies of research. <a href="#fn2-ref">↩</a></p>

            <p class="footnote-item" id="fn3"><strong>[3]</strong> Thomas Dietz quoted in Mervis, "Congress is using more science." Dietz is a sociologist at Michigan State University who was not involved in the study. <a href="#fn3-ref">↩</a></p>

            <p class="footnote-item" id="fn4"><strong>[4]</strong> Segun T. Aroyehun et al., "Computational analysis of US congressional speeches reveals a shift from evidence to intuition," <em>Nature Human Behaviour</em> 9, 1122-1133 (2025). DOI: 10.1038/s41562-025-02136-2. <a href="https://www.nature.com/articles/s41562-025-02136-2" target="_blank">Nature</a> <a href="#fn4-ref">↩</a></p>

            <p class="footnote-item" id="fn5"><strong>[5]</strong> Study Finds press summary, "'Truth Decay': Congressional Speeches Have Never Been Less Evidence-Based, Researchers Warn," April 11, 2025. The study found that "the steepest decline in evidence-based speech during the 2021-2022 session came from Republicans." <a href="https://studyfinds.org/congressional-speeches-less-evidence-based/" target="_blank">Study Finds</a> <a href="#fn5-ref">↩</a></p>

            <p class="footnote-item" id="fn6"><strong>[6]</strong> Aroyehun et al., "Computational analysis," p. 1123. The paper argues that exclusive reliance on intuition prevents evidence from serving as an arbiter between competing positions. <a href="#fn6-ref">↩</a></p>

            <p class="footnote-item" id="fn7"><strong>[7]</strong> Center for Media and Public Affairs at George Mason University, "Study: Media Fact-Checker Says Republicans Lie More," May 28, 2013. The study examined 100 statements from January 20 through May 22, 2013. <a href="https://cmpa.gmu.edu/study-media-fact-checker-says-republicans-lie-more/" target="_blank">CMPA</a> <a href="#fn7-ref">↩</a></p>

            <p class="footnote-item" id="fn8"><strong>[8]</strong> Bill Adair's statement upon retirement from PolitiFact, October 2024, as reported in the PolitiFact Wikipedia article citing the original interview. <a href="https://en.wikipedia.org/wiki/PolitiFact" target="_blank">Wikipedia</a> <a href="#fn8-ref">↩</a></p>

            <p class="footnote-item" id="fn9"><strong>[9]</strong> Eric Ostermeier, "Selection Bias? PolitiFact Rates Republican Statements as False at 3 Times the Rate of Democrats," Smart Politics (University of Minnesota), February 10, 2011. Ostermeier analyzed 511 PolitiFact stories from January 2010 through January 2011. <a href="https://smartpolitics.lib.umn.edu/2011/02/10/selection-bias-politifact-rate/" target="_blank">Smart Politics</a> <a href="#fn9-ref">↩</a></p>

            <p class="footnote-item" id="fn10"><strong>[10]</strong> Anthony Howell et al., "Prestige over merit: An adapted audit of LLM bias in peer review," arXiv:2509.15122, September 2025. The study found that "prestige-linked priors embedded in training data shape paper-level outcomes." <a href="https://arxiv.org/abs/2509.15122" target="_blank">arXiv</a> <a href="#fn10-ref">↩</a></p>

            <p class="footnote-item" id="fn11"><strong>[11]</strong> For an overview of how RAG systems prioritize sources, see Ahrefs, "How to Earn LLM Citations to Build Traffic & Authority," November 2025. The article notes that "LLMs rely heavily on Google's E-E-A-T principles to assess reliability." <a href="https://ahrefs.com/blog/llm-citations/" target="_blank">Ahrefs</a> <a href="#fn11-ref">↩</a></p>

            <p class="footnote-item" id="fn12"><strong>[12]</strong> Techmagnate, "How to Get Cited by LLMs, Guide to LLM Seeding," October 2025. <a href="https://www.techmagnate.com/blog/llm-citation-guide/" target="_blank">Techmagnate</a> <a href="#fn12-ref">↩</a></p>

            <p class="footnote-item" id="fn13"><strong>[13]</strong> Suyash Fulay et al., "On the Relationship between Truth and Political Bias in Language Models," <em>Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</em>, pp. 9004-9018. DOI: 10.18653/v1/2024.emnlp-main.508. <a href="https://aclanthology.org/2024.emnlp-main.508/" target="_blank">ACL Anthology</a> <a href="#fn13-ref">↩</a></p>
        </div>
    </div>

    <footer class="site-footer">
        <div class="site-footer-inner">
            <p><a href="paper-2-gatekeeper.html">← Paper II: Information Gatekeeper</a>  -  <a href="paper-4-neutrality.html">Paper IV: Political Neutrality ←'</a></p>
            <p>© 2025 KyanosTech. <a href="../index.html">Return to index</a>.</p>
        </div>
    </footer>
</body>
</html>
